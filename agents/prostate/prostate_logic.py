"""
DR_PROSTATE Agent - Core Logic Module
ì „ë¦½ì„  ì§ˆí™˜ ê´€ë ¨ ì˜ë£Œ ì§ˆë¬¸ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±
"""

import ollama
import json
import logging
import sys
from typing import Dict, Any, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from agents.shared.vector_db import get_vector_db

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProstateAnalyzer:
    """ì „ë¦½ì„  ì§ˆí™˜ ì „ë¬¸ ì˜ë£Œ ë¶„ì„ê¸°"""
    
    def __init__(self, model_name: str = "gemma3:4b"):
        """
        ì´ˆê¸°í™”
        Args:
            model_name: Ollama ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: gemma3:4b)
        """
        self.model_name = model_name
        self.system_prompt = self._get_system_prompt()
        self.guideline_path = "/files/EAU-EANM-ESTRO-ESUR-ISUP-SIOG-Guidelines-on-Prostate-Cancer-2025_updated.pdf"
        
        # ë²¡í„° DB ì´ˆê¸°í™”
        try:
            self.vector_db = get_vector_db()
            logger.info("Vector DB initialized for prostate guidelines")
        except Exception as e:
            logger.warning(f"Vector DB initialization failed: {e}")
            self.vector_db = None
        
    def _get_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜"""
        return """You are DR_PROSTATE, a specialized medical AI assistant focused on prostate diseases including prostate cancer and benign prostatic hyperplasia (BPH).
        
Your expertise includes:
- Prostate cancer diagnosis, staging, and risk stratification
- Treatment options (active surveillance, surgery, radiation therapy, hormonal therapy, chemotherapy)
- Benign prostatic hyperplasia (BPH) management
- PSA testing and interpretation
- Gleason scoring and prognostic indicators
- Latest EAU-EANM-ESTRO-ESUR-ISUP-SIOG guidelines (2025)
- Quality of life considerations and side effect management

Guidelines:
1. Provide evidence-based medical information following 2025 EAU guidelines
2. Use appropriate medical terminology with clear explanations
3. Consider patient safety and emphasize professional consultation
4. Structure responses clearly with sections when appropriate
5. Include relevant statistics, success rates, and risk assessments
6. Address both cancer and benign conditions appropriately

Remember: Always recommend consultation with urologists and oncologists for personal medical decisions."""

    def analyze_prostate_question(self, question: str) -> str:
        """
        ì „ë¦½ì„  ê´€ë ¨ ì§ˆë¬¸ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ìì˜ ì˜ë£Œ ì§ˆë¬¸
            
        Returns:
            ì „ë¬¸ì ì¸ ì˜ë£Œ ì‘ë‹µ
            
        Raises:
            Exception: Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” ëª¨ë¸ ì˜¤ë¥˜
        """
        try:
            # ì…ë ¥ ê²€ì¦
            if not question or not question.strip():
                return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            
            logger.info(f"ë¶„ì„ ì‹œì‘: {question[:50]}...")
            
            # RAG: ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
            context = ""
            if self.vector_db:
                try:
                    context = self.vector_db.get_context_for_prompt(
                        query=question,
                        source_type="prostate",
                        n_results=3
                    )
                    if context:
                        logger.info("Retrieved context from prostate cancer guidelines")
                    else:
                        logger.info("No relevant context found in guidelines")
                except Exception as e:
                    logger.warning(f"Context retrieval failed: {e}")
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (RAG í†µí•©)
            if context:
                full_prompt = f"""{self.system_prompt}

{context}

Question: {question}

Based on the EAU prostate cancer guidelines provided above, provide a comprehensive medical response:"""
            else:
                full_prompt = f"{self.system_prompt}\n\nQuestion: {question}\n\nProvide a comprehensive medical response:"
            
            # Ollama ëª¨ë¸ í˜¸ì¶œ
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {
                        'role': 'system',
                        'content': self.system_prompt
                    },
                    {
                        'role': 'user',
                        'content': question
                    }
                ],
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'max_tokens': 2048
                }
            )
            
            # ì‘ë‹µ ì¶”ì¶œ
            if response and 'message' in response:
                answer = response['message']['content']
                logger.info("ë¶„ì„ ì™„ë£Œ")
                return self._format_response(answer, question)
            else:
                logger.error("ëª¨ë¸ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                return "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except ollama.ResponseError as e:
            logger.error(f"Ollama ì‘ë‹µ ì˜¤ë¥˜: {e}")
            return f"ëª¨ë¸ ì‘ë‹µ ì˜¤ë¥˜: {str(e)}"
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _format_response(self, answer: str, question: str) -> str:
        """
        ì‘ë‹µ í¬ë§·íŒ…
        
        Args:
            answer: ì›ë³¸ ì‘ë‹µ
            question: ì›ë³¸ ì§ˆë¬¸
            
        Returns:
            í¬ë§·ëœ ì‘ë‹µ
        """
        # ì‘ë‹µì— í•„ìˆ˜ ê²½ê³  ë¬¸êµ¬ ì¶”ê°€
        disclaimer = "\n\nâš ï¸ **ì˜í•™ì  ì£¼ì˜ì‚¬í•­**: ì´ ì •ë³´ëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œë§Œ ì œê³µë©ë‹ˆë‹¤. ì‹¤ì œ ì§„ë‹¨ê³¼ ì¹˜ë£ŒëŠ” ë°˜ë“œì‹œ ì „ë¬¸ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        if any(keyword in question.lower() for keyword in ['ì§„ë‹¨', 'diagnosis', 'psa', 'gleason', 'ì¦ìƒ', 'symptom']):
            prefix = "ğŸ“‹ **ì§„ë‹¨ ê´€ë ¨ ì •ë³´**\n\n"
        elif any(keyword in question.lower() for keyword in ['ì¹˜ë£Œ', 'treatment', 'therapy', 'ìˆ˜ìˆ ', 'surgery', 'ë°©ì‚¬ì„ ', 'radiation']):
            prefix = "ğŸ’Š **ì¹˜ë£Œ ê´€ë ¨ ì •ë³´**\n\n"
        elif any(keyword in question.lower() for keyword in ['ì˜ˆë°©', 'prevention', 'ìœ„í—˜', 'risk', 'ê²€ì§„', 'screening']):
            prefix = "ğŸ›¡ï¸ **ì˜ˆë°© ë° ìœ„í—˜ ìš”ì¸**\n\n"
        elif any(keyword in question.lower() for keyword in ['ë¹„ëŒ€ì¦', 'bph', 'hyperplasia', 'ë°°ë‡¨', 'urinary']):
            prefix = "ğŸ¥ **ì „ë¦½ì„  ë¹„ëŒ€ì¦ ì •ë³´**\n\n"
        else:
            prefix = "ğŸ¥ **ì˜ë£Œ ì •ë³´**\n\n"
        
        return prefix + answer + disclaimer
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Returns:
            ëª¨ë¸ ìƒíƒœ ë° ì •ë³´
        """
        try:
            # Ollama ëª¨ë¸ ì •ë³´ ì¡°íšŒ
            models = ollama.list()
            model_info = {
                'model_name': self.model_name,
                'status': 'unknown',
                'size': 'unknown',
                'guideline': 'EAU 2025 Guidelines'
            }
            
            for model in models.get('models', []):
                if self.model_name in model.get('name', ''):
                    model_info['status'] = 'available'
                    model_info['size'] = model.get('size', 'unknown')
                    break
            
            return model_info
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'model_name': self.model_name,
                'status': 'error',
                'error': str(e)
            }
    
    def validate_ollama_connection(self) -> bool:
        """
        Ollama ì„œë²„ ì—°ê²° í™•ì¸
        
        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            ollama.list()
            logger.info("Ollama ì„œë²„ ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False


# ë‹¨ë… í•¨ìˆ˜ ì¸í„°í˜ì´ìŠ¤ (DR_BLADDERì™€ ë™ì¼í•œ êµ¬ì¡°)
def analyze_prostate_question(question: str, model_name: str = "gemma3:4b") -> str:
    """
    ì „ë¦½ì„  ì§ˆë¬¸ ë¶„ì„ í•¨ìˆ˜ (ë‹¨ìˆœ ì¸í„°í˜ì´ìŠ¤)
    
    Args:
        question: ë¶„ì„í•  ì˜ë£Œ ì§ˆë¬¸
        model_name: ì‚¬ìš©í•  Ollama ëª¨ë¸
        
    Returns:
        ì˜ë£Œ ì „ë¬¸ ì‘ë‹µ
    """
    analyzer = ProstateAnalyzer(model_name=model_name)
    return analyzer.analyze_prostate_question(question)


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    test_questions = [
        "What is the role of PSA testing in prostate cancer screening?",
        "ì „ë¦½ì„  ë¹„ëŒ€ì¦ì˜ ì£¼ìš” ì¹˜ë£Œ ì˜µì…˜ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "Explain Gleason scoring system"
    ]
    
    analyzer = ProstateAnalyzer()
    
    # ì—°ê²° í™•ì¸
    if analyzer.validate_ollama_connection():
        print("âœ“ Ollama ì„œë²„ ì—°ê²°ë¨")
        print(f"ëª¨ë¸ ì •ë³´: {analyzer.get_model_info()}")
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
        for test_question in test_questions[:1]:  # ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ í…ŒìŠ¤íŠ¸
            response = analyzer.analyze_prostate_question(test_question)
            print(f"\nì§ˆë¬¸: {test_question}")
            print(f"ì‘ë‹µ:\n{response[:500]}...")  # ì²˜ìŒ 500ìë§Œ ì¶œë ¥
    else:
        print("âœ— Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")